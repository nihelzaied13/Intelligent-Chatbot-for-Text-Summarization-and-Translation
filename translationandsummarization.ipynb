{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a larger T5 model for potentially better translation quality\n",
    "model_name = \"t5-base\"  \n",
    "model1 = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de découpe du texte en segments\n",
    "def split_text(text, max_length=512):\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    return [tokens[i:i + max_length] for i in range(0, len(tokens), max_length)]\n",
    "\n",
    "# Fonction de résumé pour un texte long\n",
    "def summarize_long_text(text):\n",
    "    segments = split_text(text)\n",
    "    summaries = []\n",
    "    for segment in segments:\n",
    "        segment_text = tokenizer.decode(segment, skip_special_tokens=True)\n",
    "        summary = summarize_text(segment_text)  # Utilise la fonction de résumé sur chaque segment\n",
    "        summaries.append(summary)\n",
    "    return \" \".join(summaries)  # Combine les résumés partiels\n",
    "\n",
    "# Fonction de résumé pour un segment\n",
    "def summarize_text(text):\n",
    "    input_text = \"summarize: \" + text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    try:\n",
    "        # Génération du résumé\n",
    "        summary_ids = model.generate(\n",
    "            input_ids,\n",
    "            num_beams=4,\n",
    "            max_length=100,\n",
    "            min_length=30,\n",
    "            early_stopping=True,\n",
    "            no_repeat_ngram_size=2\n",
    "        )\n",
    "        \n",
    "        # Décodage et affichage du résumé\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    \n",
    "    except IndexError:\n",
    "        print(\"Erreur : un segment de texte a dépassé la longueur maximale de tokens supportée par le modèle.\")\n",
    "        return \"Résumé indisponible pour ce segment.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: l'intelligence artificielle (IA) est un domaine en plein essor qui a des applications variées . malgré ses nombreux avantages, it soulève également des préoccupations éthiques et sociales, notamment dans ce qui concerne la confidentialité des données, la discrimination algorithmique y'impact sur la société.\n"
     ]
    }
   ],
   "source": [
    "# Example text to summarize\n",
    "text_to_summarize = \"L'intelligence artificielle (IA) est un domaine en plein essor qui a des applications variées, allant de la médecine à l'industrie, en passant par l'éducation et les transports. Les systèmes d'IA sont capables d'apprendre, de raisonner et de prendre des décisions en analysant de grandes quantités de données. Ces technologies reposent sur des algorithmes sophistiqués et des modèles mathématiques qui permettent d'optimiser des processus et de résoudre des problèmes complexes. Par exemple, en médecine, l'IA est utilisée pour analyser des images médicales, prédire des maladies et personnaliser les traitements en fonction des caractéristiques spécifiques de chaque patient. De plus, l'IA joue un rôle clé dans le développement des voitures autonomes, où elle permet aux véhicules de naviguer de manière sûre sans intervention humaine, en utilisant des capteurs et des données en temps réel. Cependant, malgré ses nombreux avantages, l'IA soulève également des préoccupations éthiques et sociales, notamment en ce qui concerne la confidentialité des données, la discrimination algorithmique et l'impact sur l'emploi. Il est donc essentiel de développer des cadres réglementaires et éthiques pour guider le développement de l'IA et garantir qu'elle soit utilisée de manière responsable et bénéfique pour la société.\"\n",
    "summary = summarize_text(text_to_summarize)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to C:\\Users\\Nihel ZAIED\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Replace with your token\n",
    "token = \"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\"\n",
    "login(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Charger le modèle et le tokenizer pour la traduction de l'anglais vers le français\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"  # Nom corrigé du modèle\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: El modelo de transformador procesa texto en pasos paralelos utilizando técnicas de aprendizaje profundo.\n"
     ]
    }
   ],
   "source": [
    "def get_model_name(source_lang, target_lang):\n",
    "    return f\"Helsinki-NLP/opus-mt-{source_lang}-{target_lang}\"\n",
    "\n",
    "\n",
    "# Translation Function (from any source language to any target language)\n",
    "def translate_text(text, source_lang, target_lang):\n",
    "    # Get the model name dynamically based on the source and target language\n",
    "    model_name = get_model_name(source_lang, target_lang)\n",
    "    \n",
    "    # Load the MarianMT model and tokenizer for the specific language pair\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n",
    "    input_token_count = len(input_ids[0])  # Count the number of tokens in the input\n",
    "    \n",
    "    # Generate translation\n",
    "    translated_ids = model.generate(input_ids, \n",
    "                                    num_beams=4, \n",
    "                                    max_length=100,  # Adjust max_length for more detailed translations\n",
    "                                    early_stopping=True,\n",
    "                                    no_repeat_ngram_size=2)  # Prevent repetition\n",
    "    \n",
    "    # Decode the translation\n",
    "    translation = tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Count the number of tokens in the output (translation)\n",
    "    output_token_count = len(tokenizer.encode(translation, add_special_tokens=False))\n",
    "    \n",
    "    return translation\n",
    "\n",
    "# Example text to translate (from English to Spanish)\n",
    "text_to_translate = \"The transformer model processes text in parallel steps using deep learning techniques.\"\n",
    "source_language = \"en\"  # English\n",
    "target_language = \"es\"  # Spanish\n",
    "\n",
    "# Perform translation\n",
    "translation = translate_text(text_to_translate, source_language, target_language)\n",
    "\n",
    "# Print the result\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation: ويقوم نموذج المحوِّل بتصنيف النص على مراحل متوازية باستخدام تقنيات التعلم العميق.\n"
     ]
    }
   ],
   "source": [
    "# Exemple de texte à traduire (du français vers l'arabe)\n",
    "text_to_translate = \"Le modèle de transformateur traite le texte en étapes parallèles en utilisant des techniques d'apprentissage profond.\"\n",
    "source_language = \"fr\"  # Français\n",
    "target_language = \"ar\"  # Arabe\n",
    "\n",
    "# Effectuer la traduction\n",
    "translation = translate_text(text_to_translate, source_language, target_language)\n",
    "\n",
    "# Afficher le résultat\n",
    "print(\"Translation:\", translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation du Chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def chatbot():\n",
    "    # Greet the user and ask what they want to do\n",
    "    print(\"Hello! How can I assist you today?\")\n",
    "    print(\"You can either type 'summarize' or 'translate'.\")\n",
    "    \n",
    "    while True:\n",
    "        # Ask the user for their choice (summarize or translate)\n",
    "        action = input(\"\\nDo you want to 'summarize' or 'translate'? Type 'exit' to quit: \").strip().lower()\n",
    "\n",
    "        if action == \"exit\":\n",
    "            print(\"Goodbye! Have a great day!\")\n",
    "            break\n",
    "\n",
    "        if action == \"summarize\":\n",
    "            # Ask for the text to summarize\n",
    "            text_to_summarize = input(\"Please provide the text you want to summarize: \")\n",
    "            print(summarize_text(text_to_summarize))  # Summarize and display\n",
    "\n",
    "        elif action == \"translate\":\n",
    "            # Ask for the source and target language\n",
    "            lang_input = input(\"Please specify the source and target language (e.g., 'en to es'): \").strip()\n",
    "            \n",
    "            # Parse the languages and text\n",
    "            try:\n",
    "                source_lang, target_lang = lang_input.split(\" to \")\n",
    "                text_to_translate = input(f\"Please provide the text you want to translate from {source_lang} to {target_lang}: \")\n",
    "                print(translate_text(text_to_translate, source_lang, target_lang))  # Translate and display\n",
    "            except ValueError:\n",
    "                print(\"Error: Please use the format 'en to es' for languages.\")\n",
    "\n",
    "        else:\n",
    "            print(\"Invalid choice. Please type 'summarize' or 'translate'.\")\n",
    "\n",
    "# Start the chatbot\n",
    "chatbot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
